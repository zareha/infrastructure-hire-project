2021-08-23

Recieved AWS Management console from "Boyd Hemphill <boyd.hemphill@contrastsecurity.com>"

>> Hope you had a great weekend.  I was well way from my computer for most of it. 
>> You'll find we work hard to have calm weekends on the team. Ironically this didn't 
>> seem to serve us - or you - well in
>> this case!  Sorry about that.
>>
>>    Below is the boiler plate email, creds at the bottom.
>>    You are doing project 3
>>        You are the first person to make it this far so we will expect​ criticism 
>> during next phase
>>
>> I know both the team and I are looking forward to what you have to show off!
>> Boyd
>> ----
>>
>>
>> Zareh
>>
>> We've put together an AWS coding project for you to demonstrate your thought 
>> processes and skill set. We believe it should take 3 to 5 hours. Ultimately that is
>> up to you. The goal is to create 
>> infrastructure for an application running inside of AWS and communicate with us 
>> about your code in the same way we would at work, in a code review.
>>
>> As part of this effort we have created an AWS account. This account will be open 
>> for the duration of the interview process. Your code review and interview is 
>> scheduled for {DATE BY KEVIN DUNN}. Life happens,
>> so if you find you need to reschedule please let us know.
>>
>>
>> The Project
>>
>> You can find the project on our GitHub, https://github.com/Contrast-Security-
>> OSS/infrastructure-hire-project. We ask that you fork the project, and complete the 
>> work within your own personal repository. If you have concerns around privacy, 
>> please duplicate the repository (https://help.github.com/en/articles/duplicating-a-
>> repository), and add behemphi and cbuto as a collaborator to your private copy.
>>
>> At Contrast, we like to break project into sizable chunks, such that we can
>> maximize productivity across engineers. When working on this project, we recommend
>> you do that the same! Whether this be through pull requests into your master 
>> branch, or just broken down commits, we are looking to capture how you work.
>>
>> At any time, if you find that the project wording can be enhanced, or you discover 
>> a bug, feel free to open and issue or a Pull Request as we are always looking to 
>> better enhance the candidates experience.
>>
>>
>> The Interview
>>
>> On the scheduled day you will meet the Director of Cloud Engineering (the hiring 
>> manager) for a short orientation. You will have an hour with our team to review 
>> your code and engage in a deep discussion about the project, your process and the 
>> like. You will then have  45 minutes with the Director again where you will discuss 
>> team fit, roadmap and your own questions.
>>
>> This is the last step in the process.  You will hear from us as soon as we are done 
>> evaluating the candidate pool. 
>>
>> AWS Account
>> Please use the following account in any way you see fit. With that said, we ask that
>> you keep any work within the us-east-1 region, as it will make it easier for us to 
>> clean up after you complete.
>>
>> Console sign-in link: https://601815243188.signin.aws.amazon.com/console
>> username: zareh.aratoon
>> password: yW@)rXi3@s&e_AJ (Note: replaced)
>>
>>If you have difficulty with your account or need clarification on the project, don’t 
>>hesitate to reach out to ops@contrastsecuirty.com. We value the communication.
>>
>>Good luck, and we look forward to reviewing with you soon!
>>
>>
>>Boyd Hemphill | Director of Cloud Engineering
>>Contrast Security, Inc.
>>+1-512-470-6146 (mobile)
>>Welcome to the Era of Self-Protecting Software

* Logged on to the AWS Console and changed password and attached an MFA using Google Auth
* Generated AWS access key. Relevant account info below:

arn:aws:iam::601815243188:user/zareh.aratoon

AKIAYYHX33G2HJZXO77P

{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "AllowAdminAccess",
            "Effect": "Allow",
            "Action": "*",
            "Resource": "*"
        },
        {
            "Sid": "DenyIAMSAMLManagement",
            "Effect": "Deny",
            "Action": [
                "iam:UpdateSAMLProvider",
                "iam:DeleteSAMLProvider",
                "iam:CreateSAMLProvider"
            ],
            "Resource": "*"
        },
        {
            "Sid": "DenyOrgRoleChanges",
            "Effect": "Deny",
            "Action": [
                "iam:UpdateRole",
                "iam:UpdateAssumeRolePolicy",
                "iam:DeleteRole"
            ],
            "Resource": "arn:aws:iam::*:role/OrganizationAccountAccessRole"
        }
    ]
}


-------------------------------------------------------------------------------

* Forked https://github.com/Contrast-Security-OSS/infrastructure-hire-project to https://github.com/zareha/infrastructure-hire-project

>> Project 3
>>
>> We use MySQL as one of our main data stores. Since MySQL generally needs to be tuned 
>> from both a system and application perspective, Project 3 focuses on creating an RDS 
>> instance, optimizing the database configuration via parameter changes, and tuning 
>> some poorly performing queries.
>>
>> The idea behind this project is for candidates to showcase their knowledge of MySQL. 
>> Just like project 1, we welcome candidates to think outside the box and show us what 
>> they are passionate about.

* Reviewed files and comments/histoty for repo to gain unfair advantage ;)

-------------------------------------------------------------------------------
Setup DEV env with AWS CLI
* Installed vscode Insider using wsl2 to enable Remote Development features in vscode
* Installed Debian wsl2
* Installed AWS CLI v2 on Debian
https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2-linux.html

sudo apt-get update --allow-releaseinfo-change
sudo apt install -y zip
sudo apt install -y curl
curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
unzip awscliv2.zip
sudo ./aws/install

/usr/local/bin/aws --version
aws-cli/2.2.31 Python/3.8.8 Linux/5.4.72-microsoft-standard-WSL2 exe/x86_64.debian.10 prompt/off

aws configure
AWS Access Key ID [None]: AKIAYYHX33G2HJZXO77P
AWS Secret Access Key [None]: ********************************
Default region name [None]: us-east-1
Default output format [None]: json

cat ~/.aws/credentials 
[default]
aws_access_key_id = AKIAYYHX33G2HJZXO77P
aws_secret_access_key = ********************************

cat ~/.aws/config 
[default]
region = us-east-1
output = json

* Verifiy aws access key
aws iam list-access-keys
{
    "AccessKeyMetadata": [
        {
            "UserName": "zareh.aratoon",
            "AccessKeyId": "AKIAYYHX33G2HJZXO77P",
            "Status": "Active",
            "CreateDate": "2021-08-23T14:44:47+00:00"
        }
    ]
}

* Verify rds access

aws rds describe-db-instances
{
    "DBInstances": []
}

-------------------------------------------------------------------------------
Clone forked git repo

mkdir ~/dev/contrast-security
cd ~/dev/contrast-security
sudo apt-get install -y git
git clone https://github.com/zareha/infrastructure-hire-project
Cloning into 'infrastructure-hire-project'...
remote: Enumerating objects: 251, done.
remote: Counting objects: 100% (195/195), done.
remote: Compressing objects: 100% (126/126), done.
remote: Total 251 (delta 89), reused 162 (delta 65), pack-reused 56
Receiving objects: 100% (251/251), 124.53 KiB | 1.27 MiB/s, done.
Resolving deltas: 100% (104/104), done.
cd infrastructure-hire-project/
zareh@HP-Z:~/dev/contrast-security/infrastructure-hire-project$ ls
project1  project2  project3  README.md
zareh@HP-Z:~/dev/contrast-security/infrastructure-hire-project$ git status
On branch master
Your branch is up to date with 'origin/master'.

nothing to commit, working tree clean

-------------------------------------------------------------------------------
* Add terraform support and review TF files

sudo apt-get install -y software-properties-common
sudo apt-get install -y lsb-release
sudo apt-get install -y gnupg
curl -fsSL https://apt.releases.hashicorp.com/gpg | sudo apt-key add -
sudo apt-add-repository "deb [arch=$(dpkg --print-architecture)] https://apt.releases.hashicorp.com $(lsb_release -cs) main"
sudo apt-get update
sudo apt install -y terraform

NOTES: infrastructure-hire-project/project3/terraform/variables.tf
* Verify that your region matches correctly

* TODO _AFTER_ initial db creation and SQL execution
# Log queries not using indexes.
-      name  = "log_queries_not_using_indexes"
-      value = "0"
+      name  = "log_queries_not_using_indexes"
+      value = "1"      

# log all queries for future use
-      name  = "long_query_time"
-      value = "3"
+      name  = "long_query_time"
+      value = "0"

# enable the performance schema 
-      name         = "performance_schema"
-      value        = "0"
-      apply_method = "pending-reboot"

+      name         = "performance_schema"
+      value        = "1"
+      apply_method = "pending-reboot"

#disable name resolution
-      name  = "skip_name_resolve"
-      value = "OFF"
+      name  = "skip_name_resolve"
+      value = "ON"

# enable RDS performance insight
-  description = "Enable/Disable performance insights"
-  type        = bool
-  default     = false
+  description = "Enable/Disable performance insights"
+  type        = bool
+  default     = true


cd ~/dev/contrast-security/infrastructure-hire-project/project3/terraform
terraform init
Initializing modules...
- the_app_db in modules/rds-tfm
Downloading terraform-aws-modules/rds/aws 2.24.0 for the_app_db.rds...
- the_app_db.rds in .terraform/modules/the_app_db.rds
- the_app_db.rds.db_instance in .terraform/modules/the_app_db.rds/modules/db_instance
- the_app_db.rds.db_option_group in .terraform/modules/the_app_db.rds/modules/db_option_group
- the_app_db.rds.db_parameter_group in .terraform/modules/the_app_db.rds/modules/db_parameter_group
- the_app_db.rds.db_subnet_group in .terraform/modules/the_app_db.rds/modules/db_subnet_group
- vpc in modules/aws_vpc-tfm
╷
│ Error: Unsupported Terraform Core version
│ 
│   on version.tf line 2, in terraform:
│    2:   required_version = "~> 0.13.2"
│ 
│ This configuration does not support Terraform version 1.0.5. To proceed, either choose another supported Terraform version or update this version constraint. Version constraints are normally set for
│ good reason, so updating the constraint may lead to other errors or unexpected behavior.

* Grab correct version

cd
mkdir ~/dev/contrast-security/bin
cd ~/dev/contrast-security/bin
wget https://releases.hashicorp.com/terraform/0.13.2/terraform_0.13.2_linux_amd64.zip
unzip terraform_0.13.2_linux_amd64.zip
cd ~/dev/contrast-security/infrastructure-hire-project/project3/terraform/
~/dev/contrast-security/bin/terraform init
Initializing modules...

Initializing the backend...

Initializing provider plugins...
- Finding hashicorp/aws versions matching ">= 2.49.*, >= 2.49.*, >= 2.49.*, >= 2.49.*, >= 2.49.*"...
- Finding latest version of hashicorp/random...
- Installing hashicorp/aws v3.55.0...
- Installed hashicorp/aws v3.55.0 (self-signed, key ID 34365D9472D7468F)
- Installing hashicorp/random v3.1.0...
- Installed hashicorp/random v3.1.0 (self-signed, key ID 34365D9472D7468F)

Partner and community providers are signed by their developers.
If you'd like to know more about provider signing, you can read about it here:
https://www.terraform.io/docs/plugins/signing.html

The following providers do not have any version constraints in configuration,
so the latest version was installed.

To prevent automatic upgrades to new major versions that may contain breaking
changes, we recommend adding version constraints in a required_providers block
in your configuration, with the constraint strings suggested below.

* hashicorp/random: version = "~> 3.1.0"

Terraform has been successfully initialized!

You may now begin working with Terraform. Try running "terraform plan" to see
any changes that are required for your infrastructure. All Terraform commands
should now work.

If you ever set or change modules or backend configuration for Terraform,
rerun this command to reinitialize your working directory. If you forget, other
commands will detect it and remind you to do so if necessary.

 ~/dev/contrast-security/bin/terraform plan
Refreshing Terraform state in-memory prior to plan...
The refreshed state will be used to calculate this plan, but will not be
persisted to local or remote state storage.

data.aws_availability_zones.available: Refreshing state...
data.aws_caller_identity.current: Refreshing state...
module.the_app_db.module.rds.module.db_instance.data.aws_iam_policy_document.enhanced_monitoring: Refreshing state...

------------------------------------------------------------------------

An execution plan has been generated and is shown below.
Resource actions are indicated with the following symbols:
  + create

Terraform will perform the following actions:

  # module.the_app_db.aws_security_group.rds will be created
  + resource "aws_security_group" "rds" {
      + arn                    = (known after apply)
      + description            = "RDS connectivity for production the-app-db"
      + egress                 = (known after apply)
      + id                     = (known after apply)
      + ingress                = (known after apply)
      + name                   = (known after apply)
      + name_prefix            = "project3-production-the-app-db-rds-"
      + owner_id               = (known after apply)
      + revoke_rules_on_delete = false
      + tags                   = {
          + "Name"        = "project3-production-the-app-db-rds"
          + "application" = "project3"
          + "environment" = "production"
          + "role"        = "db"
        }
      + tags_all               = {
          + "Name"        = "project3-production-the-app-db-rds"
          + "application" = "project3"
          + "environment" = "production"
          + "role"        = "db"
        }
      + vpc_id                 = (known after apply)
    }

  # module.the_app_db.random_password.db_password will be created
  + resource "random_password" "db_password" {
      + id               = (known after apply)
      + keepers          = {
          + "rotator" = "1"
        }
      + length           = 16
      + lower            = true
      + min_lower        = 0
      + min_numeric      = 0
      + min_special      = 0
      + min_upper        = 0
      + number           = true
      + override_special = "_%$"
      + result           = (sensitive value)
      + special          = true
      + upper            = true
    }

  # module.vpc.aws_eip.nat[0] will be created
  + resource "aws_eip" "nat" {
      + allocation_id        = (known after apply)
      + association_id       = (known after apply)
      + carrier_ip           = (known after apply)
      + customer_owned_ip    = (known after apply)
      + domain               = (known after apply)
      + id                   = (known after apply)
      + instance             = (known after apply)
      + network_border_group = (known after apply)
      + network_interface    = (known after apply)
      + private_dns          = (known after apply)
      + private_ip           = (known after apply)
      + public_dns           = (known after apply)
      + public_ip            = (known after apply)
      + public_ipv4_pool     = (known after apply)
      + tags                 = {
          + "Name"        = "project3-production-us-east-1a"
          + "application" = "project3"
          + "environment" = "production"
        }
      + tags_all             = {
          + "Name"        = "project3-production-us-east-1a"
          + "application" = "project3"
          + "environment" = "production"
        }
      + vpc                  = true
    }

  # module.vpc.aws_internet_gateway.this[0] will be created
  + resource "aws_internet_gateway" "this" {
      + arn      = (known after apply)
      + id       = (known after apply)
      + owner_id = (known after apply)
      + tags     = {
          + "Name"        = "project3-production"
          + "application" = "project3"
          + "environment" = "production"
        }
      + tags_all = {
          + "Name"        = "project3-production"
          + "application" = "project3"
          + "environment" = "production"
        }
      + vpc_id   = (known after apply)
    }

  # module.vpc.aws_nat_gateway.this[0] will be created
  + resource "aws_nat_gateway" "this" {
      + allocation_id        = (known after apply)
      + connectivity_type    = "public"
      + id                   = (known after apply)
      + network_interface_id = (known after apply)
      + private_ip           = (known after apply)
      + public_ip            = (known after apply)
      + subnet_id            = (known after apply)
      + tags                 = {
          + "Name"        = "project3-production-us-east-1a"
          + "application" = "project3"
          + "environment" = "production"
        }
      + tags_all             = {
          + "Name"        = "project3-production-us-east-1a"
          + "application" = "project3"
          + "environment" = "production"
        }
    }

  # module.vpc.aws_route.private_nat_gateway[0] will be created
  + resource "aws_route" "private_nat_gateway" {
      + destination_cidr_block = "0.0.0.0/0"
      + id                     = (known after apply)
      + instance_id            = (known after apply)
      + instance_owner_id      = (known after apply)
      + nat_gateway_id         = (known after apply)
      + network_interface_id   = (known after apply)
      + origin                 = (known after apply)
      + route_table_id         = (known after apply)
      + state                  = (known after apply)

      + timeouts {
          + create = "5m"
        }
    }

  # module.vpc.aws_route.public_internet_gateway[0] will be created
  + resource "aws_route" "public_internet_gateway" {
      + destination_cidr_block = "0.0.0.0/0"
      + gateway_id             = (known after apply)
      + id                     = (known after apply)
      + instance_id            = (known after apply)
      + instance_owner_id      = (known after apply)
      + network_interface_id   = (known after apply)
      + origin                 = (known after apply)
      + route_table_id         = (known after apply)
      + state                  = (known after apply)

      + timeouts {
          + create = "5m"
        }
    }

  # module.vpc.aws_route_table.database[0] will be created
  + resource "aws_route_table" "database" {
      + arn              = (known after apply)
      + id               = (known after apply)
      + owner_id         = (known after apply)
      + propagating_vgws = (known after apply)
      + route            = (known after apply)
      + tags             = {
          + "Name"        = "project3-production-db"
          + "application" = "project3"
          + "environment" = "production"
        }
      + tags_all         = {
          + "Name"        = "project3-production-db"
          + "application" = "project3"
          + "environment" = "production"
        }
      + vpc_id           = (known after apply)
    }

  # module.vpc.aws_route_table.private[0] will be created
  + resource "aws_route_table" "private" {
      + arn              = (known after apply)
      + id               = (known after apply)
      + owner_id         = (known after apply)
      + propagating_vgws = (known after apply)
      + route            = (known after apply)
      + tags             = {
          + "Name"        = "project3-production-private"
          + "application" = "project3"
          + "environment" = "production"
        }
      + tags_all         = {
          + "Name"        = "project3-production-private"
          + "application" = "project3"
          + "environment" = "production"
        }
      + vpc_id           = (known after apply)
    }

  # module.vpc.aws_route_table.public[0] will be created
  + resource "aws_route_table" "public" {
      + arn              = (known after apply)
      + id               = (known after apply)
      + owner_id         = (known after apply)
      + propagating_vgws = (known after apply)
      + route            = (known after apply)
      + tags             = {
          + "Name"        = "project3-production-public"
          + "application" = "project3"
          + "environment" = "production"
        }
      + tags_all         = {
          + "Name"        = "project3-production-public"
          + "application" = "project3"
          + "environment" = "production"
        }
      + vpc_id           = (known after apply)
    }

  # module.vpc.aws_route_table_association.database[0] will be created
  + resource "aws_route_table_association" "database" {
      + id             = (known after apply)
      + route_table_id = (known after apply)
      + subnet_id      = (known after apply)
    }

  # module.vpc.aws_route_table_association.database[1] will be created
  + resource "aws_route_table_association" "database" {
      + id             = (known after apply)
      + route_table_id = (known after apply)
      + subnet_id      = (known after apply)
    }

  # module.vpc.aws_route_table_association.database[2] will be created
  + resource "aws_route_table_association" "database" {
      + id             = (known after apply)
      + route_table_id = (known after apply)
      + subnet_id      = (known after apply)
    }

  # module.vpc.aws_route_table_association.private[0] will be created
  + resource "aws_route_table_association" "private" {
      + id             = (known after apply)
      + route_table_id = (known after apply)
      + subnet_id      = (known after apply)
    }

  # module.vpc.aws_route_table_association.private[1] will be created
  + resource "aws_route_table_association" "private" {
      + id             = (known after apply)
      + route_table_id = (known after apply)
      + subnet_id      = (known after apply)
    }

  # module.vpc.aws_route_table_association.private[2] will be created
  + resource "aws_route_table_association" "private" {
      + id             = (known after apply)
      + route_table_id = (known after apply)
      + subnet_id      = (known after apply)
    }

  # module.vpc.aws_route_table_association.public[0] will be created
  + resource "aws_route_table_association" "public" {
      + id             = (known after apply)
      + route_table_id = (known after apply)
      + subnet_id      = (known after apply)
    }

  # module.vpc.aws_route_table_association.public[1] will be created
  + resource "aws_route_table_association" "public" {
      + id             = (known after apply)
      + route_table_id = (known after apply)
      + subnet_id      = (known after apply)
    }

  # module.vpc.aws_route_table_association.public[2] will be created
  + resource "aws_route_table_association" "public" {
      + id             = (known after apply)
      + route_table_id = (known after apply)
      + subnet_id      = (known after apply)
    }

  # module.vpc.aws_subnet.database[0] will be created
  + resource "aws_subnet" "database" {
      + arn                             = (known after apply)
      + assign_ipv6_address_on_creation = false
      + availability_zone               = "us-east-1a"
      + availability_zone_id            = (known after apply)
      + cidr_block                      = "10.94.251.0/24"
      + id                              = (known after apply)
      + ipv6_cidr_block_association_id  = (known after apply)
      + map_public_ip_on_launch         = false
      + owner_id                        = (known after apply)
      + tags                            = {
          + "Name"        = "project3-production-db-us-east-1a"
          + "application" = "project3"
          + "environment" = "production"
          + "subnet"      = "database"
        }
      + tags_all                        = {
          + "Name"        = "project3-production-db-us-east-1a"
          + "application" = "project3"
          + "environment" = "production"
          + "subnet"      = "database"
        }
      + vpc_id                          = (known after apply)
    }

  # module.vpc.aws_subnet.database[1] will be created
  + resource "aws_subnet" "database" {
      + arn                             = (known after apply)
      + assign_ipv6_address_on_creation = false
      + availability_zone               = "us-east-1b"
      + availability_zone_id            = (known after apply)
      + cidr_block                      = "10.94.252.0/24"
      + id                              = (known after apply)
      + ipv6_cidr_block_association_id  = (known after apply)
      + map_public_ip_on_launch         = false
      + owner_id                        = (known after apply)
      + tags                            = {
          + "Name"        = "project3-production-db-us-east-1b"
          + "application" = "project3"
          + "environment" = "production"
          + "subnet"      = "database"
        }
      + tags_all                        = {
          + "Name"        = "project3-production-db-us-east-1b"
          + "application" = "project3"
          + "environment" = "production"
          + "subnet"      = "database"
        }
      + vpc_id                          = (known after apply)
    }

  # module.vpc.aws_subnet.database[2] will be created
  + resource "aws_subnet" "database" {
      + arn                             = (known after apply)
      + assign_ipv6_address_on_creation = false
      + availability_zone               = "us-east-1c"
      + availability_zone_id            = (known after apply)
      + cidr_block                      = "10.94.253.0/24"
      + id                              = (known after apply)
      + ipv6_cidr_block_association_id  = (known after apply)
      + map_public_ip_on_launch         = false
      + owner_id                        = (known after apply)
      + tags                            = {
          + "Name"        = "project3-production-db-us-east-1c"
          + "application" = "project3"
          + "environment" = "production"
          + "subnet"      = "database"
        }
      + tags_all                        = {
          + "Name"        = "project3-production-db-us-east-1c"
          + "application" = "project3"
          + "environment" = "production"
          + "subnet"      = "database"
        }
      + vpc_id                          = (known after apply)
    }

  # module.vpc.aws_subnet.private[0] will be created
  + resource "aws_subnet" "private" {
      + arn                             = (known after apply)
      + assign_ipv6_address_on_creation = false
      + availability_zone               = "us-east-1a"
      + availability_zone_id            = (known after apply)
      + cidr_block                      = "10.94.0.0/20"
      + id                              = (known after apply)
      + ipv6_cidr_block_association_id  = (known after apply)
      + map_public_ip_on_launch         = false
      + owner_id                        = (known after apply)
      + tags                            = {
          + "Name"        = "project3-production-private-us-east-1a"
          + "application" = "project3"
          + "environment" = "production"
          + "subnet"      = "private"
        }
      + tags_all                        = {
          + "Name"        = "project3-production-private-us-east-1a"
          + "application" = "project3"
          + "environment" = "production"
          + "subnet"      = "private"
        }
      + vpc_id                          = (known after apply)
    }

  # module.vpc.aws_subnet.private[1] will be created
  + resource "aws_subnet" "private" {
      + arn                             = (known after apply)
      + assign_ipv6_address_on_creation = false
      + availability_zone               = "us-east-1b"
      + availability_zone_id            = (known after apply)
      + cidr_block                      = "10.94.16.0/20"
      + id                              = (known after apply)
      + ipv6_cidr_block_association_id  = (known after apply)
      + map_public_ip_on_launch         = false
      + owner_id                        = (known after apply)
      + tags                            = {
          + "Name"        = "project3-production-private-us-east-1b"
          + "application" = "project3"
          + "environment" = "production"
          + "subnet"      = "private"
        }
      + tags_all                        = {
          + "Name"        = "project3-production-private-us-east-1b"
          + "application" = "project3"
          + "environment" = "production"
          + "subnet"      = "private"
        }
      + vpc_id                          = (known after apply)
    }

  # module.vpc.aws_subnet.private[2] will be created
  + resource "aws_subnet" "private" {
      + arn                             = (known after apply)
      + assign_ipv6_address_on_creation = false
      + availability_zone               = "us-east-1c"
      + availability_zone_id            = (known after apply)
      + cidr_block                      = "10.94.32.0/20"
      + id                              = (known after apply)
      + ipv6_cidr_block_association_id  = (known after apply)
      + map_public_ip_on_launch         = false
      + owner_id                        = (known after apply)
      + tags                            = {
          + "Name"        = "project3-production-private-us-east-1c"
          + "application" = "project3"
          + "environment" = "production"
          + "subnet"      = "private"
        }
      + tags_all                        = {
          + "Name"        = "project3-production-private-us-east-1c"
          + "application" = "project3"
          + "environment" = "production"
          + "subnet"      = "private"
        }
      + vpc_id                          = (known after apply)
    }

  # module.vpc.aws_subnet.public[0] will be created
  + resource "aws_subnet" "public" {
      + arn                             = (known after apply)
      + assign_ipv6_address_on_creation = false
      + availability_zone               = "us-east-1a"
      + availability_zone_id            = (known after apply)
      + cidr_block                      = "10.94.96.0/20"
      + id                              = (known after apply)
      + ipv6_cidr_block_association_id  = (known after apply)
      + map_public_ip_on_launch         = true
      + owner_id                        = (known after apply)
      + tags                            = {
          + "Name"        = "project3-production-public-us-east-1a"
          + "application" = "project3"
          + "environment" = "production"
          + "subnet"      = "public"
        }
      + tags_all                        = {
          + "Name"        = "project3-production-public-us-east-1a"
          + "application" = "project3"
          + "environment" = "production"
          + "subnet"      = "public"
        }
      + vpc_id                          = (known after apply)
    }

  # module.vpc.aws_subnet.public[1] will be created
  + resource "aws_subnet" "public" {
      + arn                             = (known after apply)
      + assign_ipv6_address_on_creation = false
      + availability_zone               = "us-east-1b"
      + availability_zone_id            = (known after apply)
      + cidr_block                      = "10.94.112.0/20"
      + id                              = (known after apply)
      + ipv6_cidr_block_association_id  = (known after apply)
      + map_public_ip_on_launch         = true
      + owner_id                        = (known after apply)
      + tags                            = {
          + "Name"        = "project3-production-public-us-east-1b"
          + "application" = "project3"
          + "environment" = "production"
          + "subnet"      = "public"
        }
      + tags_all                        = {
          + "Name"        = "project3-production-public-us-east-1b"
          + "application" = "project3"
          + "environment" = "production"
          + "subnet"      = "public"
        }
      + vpc_id                          = (known after apply)
    }

  # module.vpc.aws_subnet.public[2] will be created
  + resource "aws_subnet" "public" {
      + arn                             = (known after apply)
      + assign_ipv6_address_on_creation = false
      + availability_zone               = "us-east-1c"
      + availability_zone_id            = (known after apply)
      + cidr_block                      = "10.94.128.0/20"
      + id                              = (known after apply)
      + ipv6_cidr_block_association_id  = (known after apply)
      + map_public_ip_on_launch         = true
      + owner_id                        = (known after apply)
      + tags                            = {
          + "Name"        = "project3-production-public-us-east-1c"
          + "application" = "project3"
          + "environment" = "production"
          + "subnet"      = "public"
        }
      + tags_all                        = {
          + "Name"        = "project3-production-public-us-east-1c"
          + "application" = "project3"
          + "environment" = "production"
          + "subnet"      = "public"
        }
      + vpc_id                          = (known after apply)
    }

  # module.vpc.aws_vpc.this[0] will be created
  + resource "aws_vpc" "this" {
      + arn                              = (known after apply)
      + assign_generated_ipv6_cidr_block = false
      + cidr_block                       = "10.94.0.0/16"
      + default_network_acl_id           = (known after apply)
      + default_route_table_id           = (known after apply)
      + default_security_group_id        = (known after apply)
      + dhcp_options_id                  = (known after apply)
      + enable_classiclink               = (known after apply)
      + enable_classiclink_dns_support   = (known after apply)
      + enable_dns_hostnames             = false
      + enable_dns_support               = true
      + id                               = (known after apply)
      + instance_tenancy                 = "default"
      + ipv6_association_id              = (known after apply)
      + ipv6_cidr_block                  = (known after apply)
      + main_route_table_id              = (known after apply)
      + owner_id                         = (known after apply)
      + tags                             = {
          + "Name"        = "project3-production"
          + "application" = "project3"
          + "environment" = "production"
        }
      + tags_all                         = {
          + "Name"        = "project3-production"
          + "application" = "project3"
          + "environment" = "production"
        }
    }

  # module.the_app_db.module.rds.module.db_instance.aws_db_instance.this[0] will be created
  + resource "aws_db_instance" "this" {
      + address                               = (known after apply)
      + allocated_storage                     = 25
      + allow_major_version_upgrade           = false
      + apply_immediately                     = false
      + arn                                   = (known after apply)
      + auto_minor_version_upgrade            = true
      + availability_zone                     = (known after apply)
      + backup_retention_period               = 7
      + backup_window                         = "05:37-06:07"
      + ca_cert_identifier                    = "rds-ca-2019"
      + character_set_name                    = (known after apply)
      + copy_tags_to_snapshot                 = false
      + db_subnet_group_name                  = (known after apply)
      + delete_automated_backups              = true
      + deletion_protection                   = false
      + endpoint                              = (known after apply)
      + engine                                = "mysql"
      + engine_version                        = "8.0.23"
      + engine_version_actual                 = (known after apply)
      + hosted_zone_id                        = (known after apply)
      + iam_database_authentication_enabled   = false
      + id                                    = (known after apply)
      + identifier                            = "project3-production-the-app-db-rds"
      + identifier_prefix                     = (known after apply)
      + instance_class                        = "db.t3.medium"
      + iops                                  = 0
      + kms_key_id                            = (known after apply)
      + latest_restorable_time                = (known after apply)
      + license_model                         = (known after apply)
      + maintenance_window                    = "tue:07:00-tue:07:30"
      + max_allocated_storage                 = 50
      + monitoring_interval                   = 0
      + monitoring_role_arn                   = (known after apply)
      + multi_az                              = true
      + name                                  = "the_app_db"
      + nchar_character_set_name              = (known after apply)
      + option_group_name                     = (known after apply)
      + parameter_group_name                  = (known after apply)
      + password                              = (sensitive value)
      + performance_insights_enabled          = false
      + performance_insights_kms_key_id       = (known after apply)
      + performance_insights_retention_period = (known after apply)
      + port                                  = 3306
      + publicly_accessible                   = false
      + replicas                              = (known after apply)
      + resource_id                           = (known after apply)
      + skip_final_snapshot                   = true
      + snapshot_identifier                   = (known after apply)
      + status                                = (known after apply)
      + storage_encrypted                     = true
      + storage_type                          = "gp2"
      + tags                                  = {
          + "Name"        = "project3-production-the-app-db-rds"
          + "application" = "project3"
          + "environment" = "production"
          + "role"        = "db"
        }
      + tags_all                              = {
          + "Name"        = "project3-production-the-app-db-rds"
          + "application" = "project3"
          + "environment" = "production"
          + "role"        = "db"
        }
      + timezone                              = (known after apply)
      + username                              = "admin"
      + vpc_security_group_ids                = (known after apply)

      + timeouts {
          + create = "40m"
          + delete = "40m"
          + update = "80m"
        }
    }

  # module.the_app_db.module.rds.module.db_option_group.aws_db_option_group.this[0] will be created
  + resource "aws_db_option_group" "this" {
      + arn                      = (known after apply)
      + engine_name              = "mysql"
      + id                       = (known after apply)
      + major_engine_version     = "8.0"
      + name                     = (known after apply)
      + name_prefix              = "project3-production-the-app-db-rds-"
      + option_group_description = "Option group for project3-production-the-app-db-rds"
      + tags                     = {
          + "Name"        = "project3-production-the-app-db-rds"
          + "application" = "project3"
          + "environment" = "production"
          + "role"        = "db"
        }
      + tags_all                 = {
          + "Name"        = "project3-production-the-app-db-rds"
          + "application" = "project3"
          + "environment" = "production"
          + "role"        = "db"
        }

      + timeouts {
          + delete = "15m"
        }
    }

  # module.the_app_db.module.rds.module.db_parameter_group.aws_db_parameter_group.this[0] will be created
  + resource "aws_db_parameter_group" "this" {
      + arn         = (known after apply)
      + description = "Database parameter group for project3-production-the-app-db-rds"
      + family      = "mysql8.0"
      + id          = (known after apply)
      + name        = (known after apply)
      + name_prefix = "project3-production-the-app-db-rds-"
      + tags        = {
          + "Name"        = "project3-production-the-app-db-rds"
          + "application" = "project3"
          + "environment" = "production"
          + "role"        = "db"
        }
      + tags_all    = {
          + "Name"        = "project3-production-the-app-db-rds"
          + "application" = "project3"
          + "environment" = "production"
          + "role"        = "db"
        }

      + parameter {
          + apply_method = "immediate"
          + name         = "innodb_buffer_pool_size"
          + value        = "536870912"
        }
      + parameter {
          + apply_method = "immediate"
          + name         = "innodb_log_buffer_size"
          + value        = "262144"
        }
      + parameter {
          + apply_method = "immediate"
          + name         = "innodb_log_file_size"
          + value        = "2097152"
        }
      + parameter {
          + apply_method = "immediate"
          + name         = "log_queries_not_using_indexes"
          + value        = "1"
        }
      + parameter {
          + apply_method = "immediate"
          + name         = "slow_query_log"
          + value        = "0"
        }
    }

  # module.the_app_db.module.rds.module.db_subnet_group.aws_db_subnet_group.this[0] will be created
  + resource "aws_db_subnet_group" "this" {
      + arn         = (known after apply)
      + description = "Database subnet group for project3-production-the-app-db-rds"
      + id          = (known after apply)
      + name        = (known after apply)
      + name_prefix = "project3-production-the-app-db-rds-"
      + subnet_ids  = (known after apply)
      + tags        = {
          + "Name"        = "project3-production-the-app-db-rds"
          + "application" = "project3"
          + "environment" = "production"
          + "role"        = "db"
        }
      + tags_all    = {
          + "Name"        = "project3-production-the-app-db-rds"
          + "application" = "project3"
          + "environment" = "production"
          + "role"        = "db"
        }
    }

Plan: 33 to add, 0 to change, 0 to destroy.

------------------------------------------------------------------------

Note: You didn't specify an "-out" parameter to save this plan, so Terraform
can't guarantee that exactly these actions will be performed if
"terraform apply" is subsequently run.


* ~/dev/contrast-security/bin/terraform apply
module.the_app_db.module.rds.module.db_instance.data.aws_iam_policy_document.enhanced_monitoring: Refreshing state...
data.aws_caller_identity.current: Refreshing state...
data.aws_availability_zones.available: Refreshing state...

An execution plan has been generated and is shown below.
Resource actions are indicated with the following symbols:
  + create

Terraform will perform the following actions:

*  Enter a value: yes


Error: Error modifying DB Parameter Group: InvalidParameterValue: Value: 2097152 is outside of range: 4194304-273804165120 for parameter: innodb_log_file_size
        status code: 400, request id: f64a6204-07cb-45b5-ac69-e2e21ffe376d

  on .terraform/modules/the_app_db.rds/modules/db_parameter_group/main.tf line 33, in resource "aws_db_parameter_group" "this":
  33: resource "aws_db_parameter_group" "this" {
  
  
* The value of innodb_log_file_size set to 134217728 in ~/dev/contrast-security/infrastructure-hire-project/project3/terraform/terraform.tfvars
* Additional parameters added to terraform.tfvars

  {
    name  = "innodb_log_buffer_size"
    value = "262144"
    apply_method = "pending-reboot"
  },
  {
    name  = "innodb_log_file_size"
    value = "134217728"
    apply_method = "pending-reboot"
  }
  
* ~/dev/contrast-security/infrastructure-hire-project/project3/terraform/variables.tf
    
  {
    name  = "innodb_sort_buffer_size"
    value = "262144"
    apply_method = "pending-reboot"
  },
  {
    name  = "skip_name_resolve"
    value = "OFF"
    apply_method = "pending-reboot"
  }
    
* After making the corrections I executed terraform plan && terraform apply (yes) 

module.the_app_db.module.rds.module.db_instance.aws_db_instance.this[0]: Still creating... [20m20s elapsed]
module.the_app_db.module.rds.module.db_instance.aws_db_instance.this[0]: Creation complete after 20m24s [id=project3-production-the-app-db-rds]

* Verified the results of terraform via AWS RDS Console

-------------------------------------------------------------------------------

2021-08-24 

* Enabled publicly_accessible

~/dev/contrast-security/infrastructure-hire-project/project3/terraform/modules/rds-tfm/rds.tf
publicly_accessible = true

https://registry.terraform.io/modules/terraform-aws-modules/rds/aws/latest#input_publicly_accessible
https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/db_instance#publicly_accessible

* Enabled enable_dns_hostnames and enable_dns_support 
~/dev/contrast-security/infrastructure-hire-project/project3/terraform/modules/aws_vpc-tfm/variables.tf
variable "enable_dns_hostnames" {
  description = "Should be true to enable DNS hostnames in the VPC"
  type        = bool
  default     = true
}

variable "enable_dns_support" {
  description = "Should be true to enable DNS support in the VPC"
  type        = bool
  default     = true
}

https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/vpc#enable_dns_support
https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/vpc#enable_dns_hostnames

* Ran into connectivity issue from public to RDS instance, reviewed routing, SGs and was unable to pinpoint the problem 
* Launched an EC2 instance 
* Created instance keys
* Connected via ssh as admin and added user zareh
* Added user zareh to sudoers
* Added ~/.ssh/id_rsa.pub to user zareh@18.209.245.173:/home/zareh/.ssh/authorized_keys
* logged in as user zareh to 18.209.245.173

https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AccessingInstancesLinux.html

* added 18.209.245.173 to HP /etc/hosts as contrast-security

zareh@HP-Z:~/.ssh$ ssh contrast-security
The authenticity of host 'contrast-security (18.209.245.173)' can't be established.
ECDSA key fingerprint is SHA256:1HD607uRo9/qGaYCOSIaRjS2AYIG0OhyOC0JfTzPtUg.
Are you sure you want to continue connecting (yes/no)? yes
Warning: Permanently added 'contrast-security' (ECDSA) to the list of known hosts.
Linux ip-10-94-129-250 4.19.0-14-cloud-amd64 #1 SMP Debian 4.19.171-2 (2021-01-30) x86_64

The programs included with the Debian GNU/Linux system are free software;
the exact distribution terms for each program are described in the
individual files in /usr/share/doc/*/copyright.

Debian GNU/Linux comes with ABSOLUTELY NO WARRANTY, to the extent
permitted by applicable law.
Last login: Wed Aug 25 06:54:50 2021 from 35.129.70.161
zareh@ip-10-94-129-250:~$ 

* Added support for mysql apt repo 
wget https://dev.mysql.com/get/mysql-apt-config_0.8.18-1_all.deb
sudo update
sudo apt-get install gnupg
sudo dpkg -i mysql-apt-config_0.8.18-1_all.deb 

* Added mysql-client apt
sudo apt update
sudo apt-get install mysql-client

* Added encryprted password to .mylogin.cnf
mysql_config_editor set --login-path=client --host=project3-production-the-app-db-rds.cirwkqjrdnez.us-east-1.rds.amazonaws.com --user=admin --port 3306 --password
Enter password: 

* Verifiying mysql client config
mysql_config_editor print --all
[local]
user = "admin"
password = *****
host = "project3-production-the-app-db-rds.cirwkqjrdnez.us-east-1.rds.amazonaws.com"
port = 3306

https://dev.mysql.com/doc/refman/8.0/en/mysql-config-editor.html

* Verifying client connection to RDS instance
zareh@ip-10-94-129-250:~$ mysql
Welcome to the MySQL monitor.  Commands end with ; or \g.
Your MySQL connection id is 397
Server version: 8.0.23 Source distribution

Copyright (c) 2000, 2021, Oracle and/or its affiliates.

Oracle is a registered trademark of Oracle Corporation and/or its
affiliates. Other names may be trademarks of their respective
owners.

Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.

mysql>

* Done for today, tomorrow automated test... on schedule

-------------------------------------------------------------------------------
2021-08-25

* Check character set after connecting using mysql client

mysql> show variables like '%character%';
+--------------------------+-------------------------------------------+
| Variable_name            | Value                                     |
+--------------------------+-------------------------------------------+
| character_set_client     | utf8mb4                                   |
| character_set_connection | utf8mb4                                   |
| character_set_database   | utf8mb4                                   |
| character_set_filesystem | binary                                    |
| character_set_results    | utf8mb4                                   |
| character_set_server     | utf8mb4                                   |
| character_set_system     | utf8                                      |
| character_sets_dir       | /rdsdbbin/mysql-8.0.23.R3/share/charsets/ |
+--------------------------+-------------------------------------------+

* Check status of performance_schema, since our goal is to debug performnce we will enable it if off
mysql> show variables like 'performance_schema';
+--------------------+-------+
| Variable_name      | Value |
+--------------------+-------+
| performance_schema | OFF   |
+--------------------+-------+

* Added to terraform to enforce config
  {
    name = "character-set-client-handshake"
    value = "0"
    apply_method = "pending-reboot"
  },
  {
    name = "skip-character-set-client-handshake"
    value = "1"
    apply_method = "pending-reboot"
  }
~/dev/contrast-security/infrastructure-hire-project/project3/terraform/terraform.tfvars

* Checking collation
mysql> show variables like '%collation%';
+-------------------------------+--------------------+
| Variable_name                 | Value              |
+-------------------------------+--------------------+
| collation_connection          | utf8mb4_0900_ai_ci |
| collation_database            | utf8mb4_0900_ai_ci |
| collation_server              | utf8mb4_0900_ai_ci |
| default_collation_for_utf8mb4 | utf8mb4_0900_ai_ci |
+-------------------------------+--------------------+
4 rows in set (0.00 sec)

# Log queries not using indexes.
    
mysql> show variables like 'log_queries_not_using_indexes';
+-------------------------------+-------+
| Variable_name                 | Value |
+-------------------------------+-------+
| log_queries_not_using_indexes | ON    |
+-------------------------------+-------+

  {
    name  = "slow_query_log"
    value = "1"
  }
~/dev/contrast-security/infrastructure-hire-project/project3/terraform/terraform.tfvars

show variables like 'slow_query_log';
+----------------+-------+
| Variable_name  | Value |
+----------------+-------+
| slow_query_log | ON    |
+----------------+-------+

  {
    name = "long_query_time"
    value = "0"
  }
~/dev/contrast-security/infrastructure-hire-project/project3/terraform/terraform.tfvars

mysql> show variables like 'long_query_time';
+-----------------+----------+
| Variable_name   | Value    |
+-----------------+----------+
| long_query_time | 0.000000 |
+-----------------+----------+

# enable the performance schema 
  {
    name = "performance_schema"
    value = "1"
    apply_method = "pending-reboot"
  }

~/dev/contrast-security/infrastructure-hire-project/project3/terraform/terraform.tfvars
  
mysql> show databases;
+--------------------+
| Database           |
+--------------------+
| information_schema |
| mysql              |
| performance_schema |
| sys                |
| the_app_db         |
+--------------------+
5 rows in set (0.01 sec)

#disable name resolution
  {
    name = "skip_name_resolve"
    value = "1"
    apply_method = "pending-reboot"
  }
~/dev/contrast-security/infrastructure-hire-project/project3/terraform/terraform.tfvars

* Enabled general log with output to file
  {
    name = "general_log"
    value = "1"
  },
  {
    name = "log_output"
    value = "file"
  }
mysql> show variables like 'general_log';
+---------------+-------+
| Variable_name | Value |
+---------------+-------+
| general_log   | ON    |
+---------------+-------+

mysql> show variables like 'log_output';
+---------------+-------+
| Variable_name | Value |
+---------------+-------+
| log_output    | FILE  |
+---------------+-------+

* Import schema
mysql < ./mysql/schema_and_data.sql

* Checking character set and collation for tables reveals latin1 
ALTER TABLE `classicmodels`.`customers` CHARACTER SET = utf8mb4 , COLLATE = utf8mb4_0900_ai_ci ;

* Correcting the issue using pt-online-schema-change 
pt-online-schema-change \
D=classicmodels,t=customers,h=project3-production-the-app-db-rds.cirwkqjrdnez.us-east-1.rds.amazonaws.com,u=admin --execute \
--alter="convert to character set utf8mb4 collate utf8mb4_0900_ai_ci" --alter-foreign-keys-method="auto" --ask-pass --set-vars=foreign_key_checks=0

pt-online-schema-change \
D=classicmodels,t=employees,h=project3-production-the-app-db-rds.cirwkqjrdnez.us-east-1.rds.amazonaws.com,u=admin --execute \
--alter="convert to character set utf8mb4 collate utf8mb4_0900_ai_ci" --alter-foreign-keys-method="auto" --ask-pass --set-vars=foreign_key_checks=0

pt-online-schema-change \
D=classicmodels,t=offices,h=project3-production-the-app-db-rds.cirwkqjrdnez.us-east-1.rds.amazonaws.com,u=admin --execute \
--alter="convert to character set utf8mb4 collate utf8mb4_0900_ai_ci" --alter-foreign-keys-method="auto" --ask-pass --set-vars=foreign_key_checks=0

pt-online-schema-change \
D=classicmodels,t=orderdetails,h=project3-production-the-app-db-rds.cirwkqjrdnez.us-east-1.rds.amazonaws.com,u=admin --execute \
--alter="convert to character set utf8mb4 collate utf8mb4_0900_ai_ci" --alter-foreign-keys-method="auto" --ask-pass --set-vars=foreign_key_checks=0

pt-online-schema-change \
D=classicmodels,t=orders,h=project3-production-the-app-db-rds.cirwkqjrdnez.us-east-1.rds.amazonaws.com,u=admin --execute \
--alter="convert to character set utf8mb4 collate utf8mb4_0900_ai_ci" --alter-foreign-keys-method="auto" --ask-pass --set-vars=foreign_key_checks=0

pt-online-schema-change \
D=classicmodels,t=payments,h=project3-production-the-app-db-rds.cirwkqjrdnez.us-east-1.rds.amazonaws.com,u=admin --execute \
--alter="convert to character set utf8mb4 collate utf8mb4_0900_ai_ci" --alter-foreign-keys-method="auto" --ask-pass --set-vars=foreign_key_checks=0

pt-online-schema-change \
D=classicmodels,t=productlines,h=project3-production-the-app-db-rds.cirwkqjrdnez.us-east-1.rds.amazonaws.com,u=admin --execute \
--alter="convert to character set utf8mb4 collate utf8mb4_0900_ai_ci" --alter-foreign-keys-method="auto" --ask-pass --set-vars=foreign_key_checks=0

pt-online-schema-change \
D=classicmodels,t=products,h=project3-production-the-app-db-rds.cirwkqjrdnez.us-east-1.rds.amazonaws.com,u=admin --execute \
--alter="convert to character set utf8mb4 collate utf8mb4_0900_ai_ci" --alter-foreign-keys-method="auto" --ask-pass --set-vars=foreign_key_checks=0

* Executing SQLs doesn not log to slow query log even though all parameters are enabled, 
* Solution: Set min_examined_row_limit to 1
https://mariadb.com/kb/en/server-system-variables/#min_examined_row_limit

  {
    name="min_examined_row_limit"
    value="1"
  }
~/dev/contrast-security/infrastructure-hire-project/project3/terraform/terraform.tfvars

* Wrote python and bash version of sql runner

#!/usr/bin/python3

import mysql.connector

mydb = mysql.connector.connect(
  host="project3-production-the-app-db-rds.cirwkqjrdnez.us-east-1.rds.amazonaws.com",
  user="admin",
  password="****************"
  database="classicmodels"
)
mycursor = mydb.cursor()
sql = "SELECT SQL_NO_CACHE * FROM employees ORDER BY lastname,firstName"
mycursor.execute(sql)
mresult = mycursor.fetchall()
for number in range(100):
    for x in myresult:
   print (number)

#!/bin/bash
for i in {1..100}; do
        mysql classicmodels < ./mysql/query_1.sql
done

* Analyzing queries using pt-query-digest

pt-query-digest mysql-slowquery_6.log
 
# Query 2: 100 QPS, 0.02x concurrency, ID 0xBBD119AE5142C630000307F24477150A at byte 67532
# Scores: V/M = 0.00
# Time range: 2021-08-26T06:05:52 to 2021-08-26T06:05:53
# Attribute    pct   total     min     max     avg     95%  stddev  median
# ============ === ======= ======= ======= ======= ======= ======= =======
# Count         28     100
# Exec time     19    20ms   161us   410us   201us   247us    35us   185us
# Lock time     63     7ms    53us   245us    68us    80us    21us    63us
# Rows sent     94   2.25k      23      23      23      23       0      23
# Rows examine  96   4.49k      46      46      46      46       0      46
# Query size    45   6.35k      65      65      65      65       0      65
# String:
# Databases    classicmodels
# Hosts        10.94.129.250
# Users        admin
# Query_time distribution
#   1us
#  10us
# 100us  ################################################################
#   1ms
#  10ms
# 100ms
#    1s
#  10s+
# Tables
#    SHOW TABLE STATUS FROM `classicmodels` LIKE 'employees'\G
#    SHOW CREATE TABLE `classicmodels`.`employees`\G
# EXPLAIN /*!50100 PARTITIONS*/
SELECT SQL_NO_CACHE * FROM employees ORDER BY lastName, firstName\G

# Query 8: 100 QPS, 0.02x concurrency, ID 0x3B0019F1B7EB8BC545E88BD005B5E05C at byte 134883
# This item is included in the report because it matches --limit.
# Scores: V/M = 0.00
# Time range: 2021-08-26T06:11:15 to 2021-08-26T06:11:16
# Attribute    pct   total     min     max     avg     95%  stddev  median
# ============ === ======= ======= ======= ======= ======= ======= =======
# Count         11     100
# Exec time      3    19ms   160us   356us   193us   247us    33us   176us
# Lock time     13     7ms    54us   157us    68us   103us    16us    60us
# Rows sent     45   2.25k      23      23      23      23       0      23
# Rows examine  47   4.49k      46      46      46      46       0      46
# Query size    34  14.65k     150     150     150     150       0     150
# String:
# Databases    classicmodels
# Hosts        10.94.129.250
# Users        admin
# Query_time distribution
#   1us
#  10us
# 100us  ################################################################
#   1ms
#  10ms
# 100ms
#    1s
#  10s+
# Tables
#    SHOW TABLE STATUS FROM `classicmodels` LIKE 'employees'\G
#    SHOW CREATE TABLE `classicmodels`.`employees`\G
# EXPLAIN /*!50100 PARTITIONS*/
SELECT SQL_NO_CACHE employeeNumber, lastName, firstName, extension, email, officeCode, reportsTo, jobTitle FROM employees ORDER BY lastName, firstName\G


* End of day, accomplished all tasks set - progress on track
-------------------------------------------------------------------------------
2021-08-26

* Modified all queries to use SQL_NO_CACHE
* Wrote another script to summarized execution time for all queries combined

#!/bin/bash

START_total=`date +%s`
for num in {1..7};do
  START=`date +%s` 
  echo -n "query_${num}.sql"
  ./run-sql${num}.sh &>/dev/null
  END=`date +%s` 
  echo $((END-START)) | awk '{print int($1/60)":"int($1%60)}'
done
END_total=`date +%s`
echo -n "Total: "
echo $((END_total-START_total)) | awk '{print int($1/60)":"int($1%60)}'

./run-all.sh
query_1.sql0:1
query_2.sql0:2
query_3.sql0:1
query_4.sql0:8
query_5.sql0:1
query_6.sql0:3
query_7.sql0:1
Total: 0:17

* After running the run-all.sh summary report I've identified query_4.sql and query_6.sql as slowest


* Query 1
mysql> explain select * from employees order by lastName, firstName;
+----+-------------+-----------+------------+------+---------------+------+---------+------+------+----------+----------------+
| id | select_type | table     | partitions | type | possible_keys | key  | key_len | ref  | rows | filtered | Extra          |
+----+-------------+-----------+------------+------+---------------+------+---------+------+------+----------+----------------+
|  1 | SIMPLE      | employees | NULL       | ALL  | NULL          | NULL | NULL    | NULL |   23 |   100.00 | Using filesort |
+----+-------------+-----------+------------+------+---------------+------+---------+------+------+----------+----------------+
1 row in set, 1 warning (0.00 sec)

ALTER TABLE `classicmodels`.`employees` 
ADD INDEX `index4` (`lastName` ASC, `firstName` ASC) VISIBLE;
ALTER TABLE `classicmodels`.`employees` ALTER INDEX `officeCode` INVISIBLE;

mysql> explain select lastName, firstName  from employees order by lastName, firstName;
+----+-------------+-----------+------------+-------+---------------+--------+---------+------+------+----------+-------------+
| id | select_type | table     | partitions | type  | possible_keys | key    | key_len | ref  | rows | filtered | Extra       |
+----+-------------+-----------+------------+-------+---------------+--------+---------+------+------+----------+-------------+
|  1 | SIMPLE      | employees | NULL       | index | NULL          | index4 | 404     | NULL |   23 |   100.00 | Using index |
+----+-------------+-----------+------------+-------+---------------+--------+---------+------+------+----------+-------------+;






* Query 2
mysql> explain select customerName, city, orderNumber, orderDate, productCode, quantityOrdered, priceEach
    -> from   customers    as c
    -> join   orders       as o  using (customerNumber)
    -> join   orderdetails as oe using (orderNumber)
    -> where  country = 'Norway'
    -> and    quantityOrdered between 20 and 30;
+----+-------------+-------+------------+------+------------------------+----------------+---------+--------------------------------+------+----------+-------------+
| id | select_type | table | partitions | type | possible_keys          | key            | key_len | ref                            | rows | filtered | Extra       |
+----+-------------+-------+------------+------+------------------------+----------------+---------+--------------------------------+------+----------+-------------+
|  1 | SIMPLE      | c     | NULL       | ALL  | PRIMARY                | NULL           | NULL    | NULL                           |  122 |    10.00 | Using where |
|  1 | SIMPLE      | o     | NULL       | ref  | PRIMARY,customerNumber | customerNumber | 4       | classicmodels.c.customerNumber |    3 |   100.00 | NULL        |
|  1 | SIMPLE      | oe    | NULL       | ref  | PRIMARY                | PRIMARY        | 4       | classicmodels.o.orderNumber    |    9 |    11.11 | Using where |
+----+-------------+-------+------------+------+------------------------+----------------+---------+--------------------------------+------+----------+-------------+
3 rows in set, 1 warning (0.00 sec)

ALTER TABLE `classicmodels`.`customers` 
ADD INDEX `index3` (`country` ASC) VISIBLE;
;

mysql> explain select customerName, city, orderNumber, orderDate, productCode, quantityOrdered, priceEach
    -> from   customers    as c
    -> join   orders       as o  using (customerNumber)
    -> join   orderdetails as oe using (orderNumber)
    -> where  country = 'Norway'
    -> and    quantityOrdered between 20 and 30;
+----+-------------+-------+------------+------+------------------------+----------------+---------+--------------------------------+------+----------+-------------+
| id | select_type | table | partitions | type | possible_keys          | key            | key_len | ref                            | rows | filtered | Extra       |
+----+-------------+-------+------------+------+------------------------+----------------+---------+--------------------------------+------+----------+-------------+
|  1 | SIMPLE      | c     | NULL       | ref  | PRIMARY,index3         | index3         | 202     | const                          |    1 |   100.00 | NULL        |
|  1 | SIMPLE      | o     | NULL       | ref  | PRIMARY,customerNumber | customerNumber | 4       | classicmodels.c.customerNumber |    3 |   100.00 | NULL        |
|  1 | SIMPLE      | oe    | NULL       | ref  | PRIMARY                | PRIMARY        | 4       | classicmodels.o.orderNumber    |    9 |    11.11 | Using where |
+----+-------------+-------+------------+------+------------------------+----------------+---------+--------------------------------+------+----------+-------------+
3 rows in set, 2 warnings (0.00 sec)




* Query 4
explain select employeeNumber, lastName, firstName, revenue
from   employees as e
join   (
          select salesRepEmployeeNumber, c.customerNumber
          from   customers as c
          join   orders    as o on (c.customerNumber = o.customerNumber)
          where  c.creditlimit > 50000
       ) as cust_ord on (e.employeeNumber = cust_ord.salesRepEmployeeNumber)
join   (
          select o.ordernumber, customerNumber, od.productcode
          from   orders       as o
          join   orderdetails as od using (ordernumber)
          where  o.status     like '%Shipped%'
       ) as ords on (cust_ord.customerNumber = ords.customerNumber)
join   (
          select p.productCode, sum( od.priceeach - p.buyPrice) as revenue
          from   products     as p
          join   orderdetails as od using (productcode)
          group  by 1
          having revenue > 1500
       ) as rev on (rev.productCode = ords.productCode)
;
+----+-------------+------------+------------+--------+------------------------+----------------+---------+----------------------------------------+------+----------+-------------+
| id | select_type | table      | partitions | type   | possible_keys          | key            | key_len | ref                                    | rows | filtered | Extra       |
+----+-------------+------------+------------+--------+------------------------+----------------+---------+----------------------------------------+------+----------+-------------+
|  1 | PRIMARY     | o          | NULL       | ALL    | PRIMARY,customerNumber | NULL           | NULL    | NULL                                   |  326 |    11.11 | Using where |
|  1 | PRIMARY     | c          | NULL       | eq_ref | PRIMARY                | PRIMARY        | 4       | classicmodels.o.customerNumber         |    1 |    33.33 | Using where |
|  1 | PRIMARY     | e          | NULL       | eq_ref | PRIMARY                | PRIMARY        | 4       | classicmodels.c.salesRepEmployeeNumber |    1 |   100.00 | NULL        |
|  1 | PRIMARY     | o          | NULL       | ref    | customerNumber         | customerNumber | 4       | classicmodels.o.customerNumber         |    3 |   100.00 | Using index |
|  1 | PRIMARY     | od         | NULL       | ref    | PRIMARY,productCode    | PRIMARY        | 4       | classicmodels.o.orderNumber            |    9 |   100.00 | Using index |
|  1 | PRIMARY     | <derived4> | NULL       | ref    | <auto_key0>            | <auto_key0>    | 62      | classicmodels.od.productCode           |   10 |   100.00 | NULL        |
|  4 | DERIVED     | p          | NULL       | index  | PRIMARY                | PRIMARY        | 62      | NULL                                   |  110 |   100.00 | NULL        |
|  4 | DERIVED     | od         | NULL       | ref    | productCode            | productCode    | 62      | classicmodels.p.productCode            |   27 |   100.00 | NULL        |
+----+-------------+------------+------------+--------+------------------------+----------------+---------+----------------------------------------+------+----------+-------------+
8 rows in set, 1 warning (0.00 sec)

* The first line indicates a full table scan, suspect the cause is subselect 2 'WHERE  o.status     LIKE '%Shipped%'

SELECT SQL_NO_CACHE employeeNumber, lastName, firstName, revenue
FROM   employees AS e
JOIN   (
          SELECT SQL_NO_CACHE salesRepEmployeeNumber, c.customerNumber
          FROM   customers AS c
          JOIN   orders    AS o ON (c.customerNumber = o.customerNumber)
          WHERE  c.creditlimit > 50000
       ) AS cust_ord ON (e.employeeNumber = cust_ord.salesRepEmployeeNumber)
JOIN   (
          SELECT SQL_NO_CACHE o.ordernumber, customerNumber, od.productcode
          FROM   orders       AS o
          JOIN   orderdetails AS od USING (ordernumber)
          WHERE  o.status     LIKE '%Shipped%'
       ) AS ords ON (cust_ord.customerNumber = ords.customerNumber)
JOIN   (
          SELECT SQL_NO_CACHE p.productCode, sum( od.priceeach - p.buyPrice) AS revenue
          FROM   products     AS p
          JOIN   orderdetails AS od USING (productcode)
          GROUP BY  1
          HAVING revenue > 1500
       ) AS rev ON (rev.productCode = ords.productCode)
;

* Segregate each join into its own query to identify slowest subselect

1) Subselect 1 = customers
SELECT SQL_NO_CACHE salesRepEmployeeNumber, c.customerNumber
FROM   customers AS c
JOIN   orders    AS o ON (c.customerNumber = o.customerNumber)
WHERE  c.creditlimit > 50000
  
2) Subselect 2 = orders
SELECT SQL_NO_CACHE o.ordernumber, customerNumber, od.productcode
FROM   orders       as o
JOIN   orderdetails as od using (ordernumber)
WHERE  o.status     like '%Shipped%'

3) Subselect 3 = products
SELECT SQL_NO_CACHE p.productCode, sum( od.priceeach - p.buyPrice) as revenue
FROM   products     as p
JOIN   orderdetails as od using (productcode)
GROUP BY  1
HAVING revenue > 1500

* Timing each subselect identifes subselect 2 products as the slowest
subselect 1 = 291 rows 0.078 sec
subselect 2 = 2771 rows 0.172 sec
subselect 3 = 17 rows 0.094 

* changed subselect 2 "LIKE '%Shipped%' to "= 'Shipped'" based on existing column data 'status'
* Query now uses index3 previously created for query_2

./run-all.sh
query_1.sql0:1
query_2.sql0:1
query_3.sql0:2
query_4.sql0:7
query_5.sql0:2
query_6.sql0:2
query_7.sql0:1
Total: 0:16

./run-all.sh
query_1.sql0:1
query_2.sql0:1
query_3.sql0:2
query_4.sql0:7
query_5.sql0:1
query_6.sql0:3
query_7.sql0:1
Total: 0:16

./run-all.sh
query_1.sql0:1
query_2.sql0:2
query_3.sql0:1
query_4.sql0:7
query_5.sql0:1
query_6.sql0:3
query_7.sql0:1
Total: 0:16

* query4 executed 100 times now runs 1 second faster 'in general', there are some 8 second ones that sneak in
* further analysis using MySQL's execution plan we can deduce that our change did infact have an impact
* See project3/zareh/query_4/explain2.png, we're now using index3 

https://mariadb.com/kb/en/building-the-best-index-for-a-given-select/#joins

* Query 5
mysql> explain select year(orderdate)                  as year,
    ->        sum(quantityordered * priceeach) as total
    -> from   orders
    -> inner  join orderdetails using (ordernumber)
    -> where  status = 'Shipped'
    -> group  by year
    -> having year > 2003;
+----+-------------+--------------+------------+------+---------------+---------+---------+----------------------------------+------+----------+------------------------------+
| id | select_type | table        | partitions | type | possible_keys | key     | key_len | ref                              | rows | filtered | Extra                        |
+----+-------------+--------------+------------+------+---------------+---------+---------+----------------------------------+------+----------+------------------------------+
|  1 | SIMPLE      | orders       | NULL       | ALL  | PRIMARY       | NULL    | NULL    | NULL                             |  326 |    10.00 | Using where; Using temporary |
|  1 | SIMPLE      | orderdetails | NULL       | ref  | PRIMARY       | PRIMARY | 4       | classicmodels.orders.orderNumber |    9 |   100.00 | NULL                         |
+----+-------------+--------------+------------+------+---------------+---------+---------+----------------------------------+------+----------+------------------------------+
2 rows in set, 1 warning (0.00 sec)

ALTER TABLE `classicmodels`.`orders` 
ADD INDEX `index3` (`status` ASC) VISIBLE;
;

mysql> explain select year(orderdate)                  as year,
    ->        sum(quantityordered * priceeach) as total
    -> from   orders
    -> inner  join orderdetails using (ordernumber)
    -> where  status = 'Shipped'
    -> group  by year
    -> having year > 2003;
mysql> explain select year(orderdate)                  as year,        sum(quantityordered * priceeach) as total from   orders inner  join orderdetails using (ordernumber) where  status = 'Shipped' group  by year having year > 2003;
+----+-------------+--------------+------------+------+----------------+---------+---------+----------------------------------+------+----------+-----------------+
| id | select_type | table        | partitions | type | possible_keys  | key     | key_len | ref                              | rows | filtered | Extra           |
+----+-------------+--------------+------------+------+----------------+---------+---------+----------------------------------+------+----------+-----------------+
|  1 | SIMPLE      | orders       | NULL       | ref  | PRIMARY,index3 | index3  | 62      | const                            |  303 |   100.00 | Using temporary |
|  1 | SIMPLE      | orderdetails | NULL       | ref  | PRIMARY        | PRIMARY | 4       | classicmodels.orders.orderNumber |    9 |   100.00 | NULL            |
+----+-------------+--------------+------------+------+----------------+---------+---------+----------------------------------+------+----------+-----------------+
2 rows in set, 1 warning (0.00 sec)




* Query 6 
mysql> explain select customernumber, customername
    -> from   customers
    -> where  exists( select ordernumber, sum(priceeach * quantityordered)
    ->                from        orderdetails
    ->                inner  join orders using (ordernumber)
    ->                where  customernumber = customers.customernumber
    ->                group  by ordernumber
    ->                having sum(priceeach * quantityordered) > 60000
    ->              );
+----+--------------------+--------------+------------+------+------------------------+----------------+---------+----------------------------------------+------+----------+------------------------------+
| id | select_type        | table        | partitions | type | possible_keys          | key            | key_len | ref                                    | rows | filtered | Extra                        |
+----+--------------------+--------------+------------+------+------------------------+----------------+---------+----------------------------------------+------+----------+------------------------------+
|  1 | PRIMARY            | customers    | NULL       | ALL  | NULL                   | NULL           | NULL    | NULL                                   |  122 |   100.00 | Using where                  |
|  2 | DEPENDENT SUBQUERY | orders       | NULL       | ref  | PRIMARY,customerNumber | customerNumber | 4       | classicmodels.customers.customerNumber |    3 |   100.00 | Using index; Using temporary |
|  2 | DEPENDENT SUBQUERY | orderdetails | NULL       | ref  | PRIMARY,productCode    | PRIMARY        | 4       | classicmodels.orders.orderNumber       |    9 |   100.00 | NULL                         |
+----+--------------------+--------------+------------+------+------------------------+----------------+---------+----------------------------------------+------+----------+------------------------------+
3 rows in set, 2 warnings (0.00 sec)

ALTER TABLE `classicmodels`.`customers` 
ADD INDEX `index4` (`customerNumber` ASC, `customerName` ASC) VISIBLE;
;

mysql> explain select customernumber, customername
    -> from   customers
    -> where  exists( select ordernumber, sum(priceeach * quantityordered)
    ->                from        orderdetails
    ->                inner  join orders using (ordernumber)
    ->                where  customernumber = customers.customernumber
    ->                group  by ordernumber
    ->                having sum(priceeach * quantityordered) > 60000
    ->              );
+----+--------------------+--------------+------------+-------+------------------------+----------------+---------+----------------------------------------+------+----------+------------------------------+
| id | select_type        | table        | partitions | type  | possible_keys          | key            | key_len | ref                                    | rows | filtered | Extra                        |
+----+--------------------+--------------+------------+-------+------------------------+----------------+---------+----------------------------------------+------+----------+------------------------------+
|  1 | PRIMARY            | customers    | NULL       | index | NULL                   | index4         | 206     | NULL                                   |  122 |   100.00 | Using where; Using index     |
|  2 | DEPENDENT SUBQUERY | orders       | NULL       | ref   | PRIMARY,customerNumber | customerNumber | 4       | classicmodels.customers.customerNumber |    3 |   100.00 | Using index; Using temporary |
|  2 | DEPENDENT SUBQUERY | orderdetails | NULL       | ref   | PRIMARY,productCode    | PRIMARY        | 4       | classicmodels.orders.orderNumber       |    9 |   100.00 | NULL                         |
+----+--------------------+--------------+------------+-------+------------------------+----------------+---------+----------------------------------------+------+----------+------------------------------+
3 rows in set, 2 warnings (0.00 sec)



* query_7

explain select customernumber,
       round(sum(quantityordered * priceeach)) sales,
       (case
           when sum(quantityordered * priceeach) < 10000                  then 'Silver'
           when sum(quantityordered * priceeach) between 10000 and 100000 then 'Gold'
           when sum(quantityordered * priceeach) > 100000                 then 'Platinum'
       end) customergroup
from       orderdetails
inner  join orders using (ordernumber)
where  year(shippeddate) = 2003
group  by customernumber;
+----+-------------+--------------+------------+------+------------------------+---------+---------+----------------------------------+------+----------+------------------------------+
| id | select_type | table        | partitions | type | possible_keys          | key     | key_len | ref                              | rows | filtered | Extra                        |
+----+-------------+--------------+------------+------+------------------------+---------+---------+----------------------------------+------+----------+------------------------------+
|  1 | SIMPLE      | orders       | NULL       | ALL  | PRIMARY,customerNumber | NULL    | NULL    | NULL                             |  326 |   100.00 | Using where; Using temporary |
|  1 | SIMPLE      | orderdetails | NULL       | ref  | PRIMARY                | PRIMARY | 4       | classicmodels.orders.orderNumber |    9 |   100.00 | NULL                         |
+----+-------------+--------------+------------+------+------------------------+---------+---------+----------------------------------+------+----------+------------------------------+
2 rows in set, 1 warning (0.00 sec)

* Full table scan on line 1
* We can create a composite index on table 'orders' using columns ordernumber, customernumber and shippeddate

+----+-------------+--------------+------------+-------+-------------------------------+----------------+---------+----------------------------------+------+----------+-------------+
| id | select_type | table        | partitions | type  | possible_keys                 | key            | key_len | ref                              | rows | filtered | Extra       |
+----+-------------+--------------+------------+-------+-------------------------------+----------------+---------+----------------------------------+------+----------+-------------+
|  1 | SIMPLE      | orders       | NULL       | index | PRIMARY,customerNumber,index4 | customerNumber | 4       | NULL                             |  326 |   100.00 | Using where |
|  1 | SIMPLE      | orderdetails | NULL       | ref   | PRIMARY                       | PRIMARY        | 4       | classicmodels.orders.orderNumber |    9 |   100.00 | NULL        |
+----+-------------+--------------+------------+-------+-------------------------------+----------------+---------+----------------------------------+------+----------+-------------+
2 rows in set, 1 warning (0.00 sec)

ALTER TABLE `classicmodels`.`orders` 
ADD INDEX `index4` (`orderNumber` ASC, `shippedDate` ASC, `customerNumber` ASC) VISIBLE;
;

* Now mysql does an index scan 

* Commited and pushed updates to github https://github.com/zareha/infrastructure-hire-project/
* Emailed "Boyd Hemphill <boyd.hemphill@contrastsecurity.com>"
-------------------------------------------------------------------------------
2021-08-27

* Output of mysqltuner.pl 

sudo ./mysqltuner.pl \
	--host project3-production-the-app-db-rds.cirwkqjrdnez.us-east-1.rds.amazonaws.com \
	--user admin \
	--password ************ \
	--forcemem 4096 \
	--forceswap=8192 \
	--verbose > mysqltuner-out.txt

-------- Database Metrics --------------------------------------------------------------------------
[--] There is 2 Database(s).
[--] All User Databases:
[--]  +-- TABLE : 8
[--]  +-- ROWS  : 3864
[--]  +-- DATA  : 384.0K(70.59%)
[--]  +-- INDEX : 160.0K(29.41%)
[--]  +-- SIZE  : 544.0K
[--]  +-- COLLA : 1 (utf8_bin, NULL, utf8mb4_0900_ai_ci, utf8mb4_bin, utf8_general_ci, latin1_swedish_ci)
[--]  +-- ENGIN : 1 (InnoDB, NULL, PERFORMANCE_SCHEMA, CSV)

[--] Database: classicmodels
[--]  +-- TABLE: 8
[--]  +-- COLL : 1 (utf8mb4_0900_ai_ci)
[--]  +-- ROWS : 3864
[--]  +-- DATA : 384.0K(70.59%)
[--]  +-- INDEX: 160.0K(29.41%)
[--]  +-- TOTAL: 544.0K
[--]  +-- ENGIN : 1 (InnoDB)
[OK] 1 collation for classicmodels database.
[OK] 1 engine for classicmodels database.
[--] Charsets for classicmodels database table column: utf8mb4
[OK] classicmodels table column(s) has same charset defined for all text like column(s).
[--] Collations for classicmodels database table column: utf8mb4_0900_ai_ci
[OK] classicmodels table column(s) has same collation defined for all text like column(s).

-------- Indexes Metrics ---------------------------------------------------------------------------
[--] Worst selectivity indexes:
[--] Index: PRIMARY(productCode)
[--]  +-- COLUMN      : classicmodels.products
[--]  +-- NB SEQS     : 1 sequence(s)
[--]  +-- NB COLS     : 1 column(s)
[--]  +-- CARDINALITY : 0 distinct values
[--]  +-- NB ROWS     : 110 rows
[--]  +-- TYPE        : BTREE
[--]  +-- SELECTIVITY : 0.00%
[!!] PRIMARY(productCode) has a low selectivity
[--] Index: productLine(productLine)
[--]  +-- COLUMN      : classicmodels.products
[--]  +-- NB SEQS     : 1 sequence(s)
[--]  +-- NB COLS     : 1 column(s)
[--]  +-- CARDINALITY : 0 distinct values
[--]  +-- NB ROWS     : 110 rows
[--]  +-- TYPE        : BTREE
[--]  +-- SELECTIVITY : 0.00%
[!!] productLine(productLine) has a low selectivity
[--] Index: index3(status)
[--]  +-- COLUMN      : classicmodels.orders
[--]  +-- NB SEQS     : 1 sequence(s)
[--]  +-- NB COLS     : 1 column(s)
[--]  +-- CARDINALITY : 6 distinct values
[--]  +-- NB ROWS     : 326 rows
[--]  +-- TYPE        : BTREE
[--]  +-- SELECTIVITY : 1.84%
[!!] index3(status) has a low selectivity
[--] Index: productCode(productCode)
[--]  +-- COLUMN      : classicmodels.orderdetails
[--]  +-- NB SEQS     : 1 sequence(s)
[--]  +-- NB COLS     : 1 column(s)
[--]  +-- CARDINALITY : 109 distinct values
[--]  +-- NB ROWS     : 2996 rows
[--]  +-- TYPE        : BTREE
[--]  +-- SELECTIVITY : 3.64%
[!!] productCode(productCode) has a low selectivity
[--] Index: PRIMARY(orderNumber)
[--]  +-- COLUMN      : classicmodels.orderdetails
[--]  +-- NB SEQS     : 1 sequence(s)
[--]  +-- NB COLS     : 2 column(s)
[--]  +-- CARDINALITY : 326 distinct values
[--]  +-- NB ROWS     : 2996 rows
[--]  +-- TYPE        : BTREE
[--]  +-- SELECTIVITY : 10.88%
[!!] PRIMARY(orderNumber) has a low selectivity
[--] Index: salesRepEmployeeNumber(salesRepEmployeeNumber)
[--]  +-- COLUMN      : classicmodels.customers
[--]  +-- NB SEQS     : 1 sequence(s)
[--]  +-- NB COLS     : 1 column(s)
[--]  +-- CARDINALITY : 16 distinct values
[--]  +-- NB ROWS     : 122 rows
[--]  +-- TYPE        : BTREE
[--]  +-- SELECTIVITY : 13.11%
[!!] salesRepEmployeeNumber(salesRepEmployeeNumber) has a low selectivity
[--] Index: index3(country)
[--]  +-- COLUMN      : classicmodels.customers
[--]  +-- NB SEQS     : 1 sequence(s)
[--]  +-- NB COLS     : 1 column(s)
[--]  +-- CARDINALITY : 28 distinct values
[--]  +-- NB ROWS     : 122 rows
[--]  +-- TYPE        : BTREE
[--]  +-- SELECTIVITY : 22.95%
[!!] index3(country) has a low selectivity
[--] Index: customerNumber(customerNumber)
[--]  +-- COLUMN      : classicmodels.orders
[--]  +-- NB SEQS     : 1 sequence(s)
[--]  +-- NB COLS     : 1 column(s)
[--]  +-- CARDINALITY : 98 distinct values
[--]  +-- NB ROWS     : 326 rows
[--]  +-- TYPE        : BTREE
[--]  +-- SELECTIVITY : 30.06%
[--] Index: officeCode(officeCode)
[--]  +-- COLUMN      : classicmodels.employees
[--]  +-- NB SEQS     : 1 sequence(s)
[--]  +-- NB COLS     : 1 column(s)
[--]  +-- CARDINALITY : 7 distinct values
[--]  +-- NB ROWS     : 23 rows
[--]  +-- TYPE        : BTREE
[--]  +-- SELECTIVITY : 30.43%
[--] Index: reportsTo(reportsTo)
[--]  +-- COLUMN      : classicmodels.employees
[--]  +-- NB SEQS     : 1 sequence(s)
[--]  +-- NB COLS     : 1 column(s)
[--]  +-- CARDINALITY : 7 distinct values
[--]  +-- NB ROWS     : 23 rows
[--]  +-- TYPE        : BTREE
[--]  +-- SELECTIVITY : 30.43%
[--] Unused indexes:
[!!] Index: salesRepEmployeeNumber on classicmodels.customers is not used.
[!!] Index: index3 on classicmodels.customers is not used.
[!!] Index: index4 on classicmodels.customers is not used.
[!!] Index: reportsTo on classicmodels.employees is not used.
[!!] Index: officeCode on classicmodels.employees is not used.
[!!] Index: productCode on classicmodels.orderdetails is not used.
[!!] Index: productLine on classicmodels.products is not used.

-------- Performance Metrics -----------------------------------------------------------------------
[--] Up for: 22h 50m 27s (60K q [0.736 qps], 1K conn, TX: 5M, RX: 3M)
[--] Reads / Writes: 99% / 1%
[--] Binary logging is enabled (GTID MODE: OFF_PERMISSIVE)
[--] Physical Memory     : 4.0G
[--] Max MySQL memory    : 20.2G
[--] Other process memory: 64.8M
[--] Total buffers: 544.2M global + 65.5M per thread (308 max threads)
[--] P_S Max memory usage: 72B
[--] Galera GCache Max memory usage: 0B
[--] Global Buffers
[--]  +-- Key Buffer: 16.0M
[--]  +-- Max Tmp Table: 16.0M
[--] Per Thread Buffers
[--]  +-- Read Buffer: 256.0K
[--]  +-- Read RND Buffer: 512.0K
[--]  +-- Sort Buffer: 256.0K
[--]  +-- Thread stack: 256.0K
[--]  +-- Join Buffer: 256.0K
[--] Binlog Cache Buffers
[--]  +-- Binlog Cache: 32.0K
[OK] Maximum reached memory usage: 871.8M (21.28% of installed RAM)
[!!] Maximum possible memory usage: 20.2G (505.82% of installed RAM)
[!!] Overall possible memory usage with other process exceeded memory
[!!] Slow queries: 96% (58K/60K)
[OK] Highest usage of available connections: 1% (5/308)
[OK] Aborted connections: 0.00%  (0/1081)
[--] Query cache have been removed in MySQL 8
[OK] Sorts requiring temporary tables: 0% (15 temp sorts / 3K sorts)
[OK] No joins without indexes
[OK] Temporary tables created on disk: 9% (429 on disk / 4K total)
[OK] Thread cache hit rate: 99% (5 created / 1K connections)
[OK] Table cache hit rate: 98% (67K hits / 68K requests)
[OK] table_definition_cache(2000) is upper than number of tables(343)
[OK] Open file limit used: 0% (4/65K)
[OK] Table locks acquired immediately: 100% (1K immediate / 1K locks)
[OK] Binlog cache memory access: 99.69% (325 Memory / 326 Total)

-------- InnoDB Metrics ----------------------------------------------------------------------------
[--] InnoDB is enabled.
[--] InnoDB Buffers
[--]  +-- InnoDB Buffer Pool: 512.0M
[--]  +-- InnoDB Buffer Pool Instances: 1
[--]  +-- InnoDB Buffer Pool Chunk Size: 128.0M
[--]  +-- InnoDB Log File Size: 128.0M
[--]  +-- InnoDB Log File In Group: 2
[--]  +-- InnoDB Total Log File Size: 256.0M(50 % of buffer pool)
[--]  +-- InnoDB Log Buffer: 256.0K
[--]  +-- InnoDB Log Buffer Free: 30.4K
[--]  +-- InnoDB Log Buffer Used: 32.0K
[--] InnoDB Thread Concurrency: 0
[OK] InnoDB File per table is activated
[OK] InnoDB buffer pool / data size: 512.0M/560.0K
[!!] Ratio InnoDB log file size / InnoDB Buffer pool size (50 %): 128.0M * 2/512.0M should be equal to 25%
[OK] InnoDB buffer pool instances: 1
[--] Number of InnoDB Buffer Pool Chunk : 4 for 1 Buffer Pool Instance(s)
[OK] Innodb_buffer_pool_size aligned with Innodb_buffer_pool_chunk_size & Innodb_buffer_pool_instances
[OK] InnoDB Read buffer efficiency: 99.08% (477378 hits/ 481792 total)
[OK] InnoDB Write log efficiency: 91.16% (34612 hits/ 37967 total)
[OK] InnoDB log waits: 0.00% (0 waits / 3355 writes)

-------- Recommendations ---------------------------------------------------------------------------
General recommendations:
    setup swappiness lower or equals to 10
    setup Max running number events greater than 1M
    Remove unused indexes.
    MySQL was started within the last 24 hours - recommendations may be inaccurate
    Reduce your overall MySQL memory footprint for system stability
    Dedicate this server to your database for highest performance.
    Before changing innodb_log_file_size and/or innodb_log_files_in_group read this: https://bit.ly/2TcGgtU
Variables to adjust:
  *** MySQL's maximum memory usage is dangerously high ***
  *** Add RAM before increasing MySQL buffer variables ***
    vm.swappiness <= 10 (echo 10 > /proc/sys/vm/swappiness)
    fs.aio-max-nr > 1M (echo 1048576 > /proc/sys/fs/aio-max-nr)
    innodb_log_file_size should be (=64M) if possible, so InnoDB total log files size equals to 25% of buffer pool size.
    
* Some recomendations by mysqltuner.pl are unactionable, first 2 are meant for the instance's kernel
* Lowered value of innodb_log_file_size from 134217728 to 67108864
  {
    name  = "innodb_log_file_size"
    value = "67108864"
    apply_method = "pending-reboot"
  }
  
* Identified unused indexes, all are part of the default schemema - will keep
[--] Unused indexes:
[!!] Index: salesRepEmployeeNumber on classicmodels.customers is not used.
[!!] Index: index3 on classicmodels.customers is not used.
[!!] Index: index4 on classicmodels.customers is not used.
[!!] Index: reportsTo on classicmodels.employees is not used.
[!!] Index: officeCode on classicmodels.employees is not used.
[!!] Index: productCode on classicmodels.orderdetails is not used.
[!!] Index: productLine on classicmodels.products is not used.

References
https://aws.amazon.com/blogs/database/best-practices-for-configuring-parameters-for-amazon-rds-for-mysql-part-1-parameters-related-to-performance/
https://aws.amazon.com/blogs/database/best-practices-for-configuring-parameters-for-amazon-rds-for-mysql-part-2-parameters-related-to-replication/
https://aws.amazon.com/blogs/database/best-practices-for-configuring-parameters-for-amazon-rds-for-mysql-part-3-parameters-related-to-security-operational-manageability-and-connectivity-timeout/
https://mariadb.com/kb/en/building-the-best-index-for-a-given-select/
https://mariadb.com/kb/en/slow-query-log-overview/
https://dev.mysql.com/doc/workbench/en/wb-performance-explain.html




--[ ACTIONALBE ITEMS/BUGS/SUGGESTIONS ]---------------------------------------------------------------------

* Instructions:

  1) State which availability zone should be used, not all zones are created equal.

  2) Describe how the user should connect to RDS instance, current terraform configs stand up an RDS instance with ~15 subnets and will now allow 
  for remote connectivity even if allowed. Define which availability zone should be used.

  3) Assign someone from the team as the primary source of contact.
  
  =============================================================================

* AWS:
  AWS IAM: Unable to deativate AWS API Key
  Issue: The user account zareh.aratoon does not have permission to deactivate AWS IAM keys.
         Being unable to disable AWS IAM keys is important to maintaining a secure AWS account in case API keys are leaked
         Will detail impact during call.
         See project3/zareh/bugs/iam-permission/iam-permission-missing.png
         
  Suggestion: Add full IAM control to test users
  
  =============================================================================
  
* Terraform
  Version: ~> 0.13.2 required
  ╷
│ Error: Unsupported Terraform Core version
│ 
│   on version.tf line 2, in terraform:
│    2:   required_version = "~> 0.13.2"
│ 
│ This configuration does not support Terraform version 1.0.5. To proceed, either choose another supported Terraform version or update this version constraint. Version constraints are normally set for
│ good reason, so updating the constraint may lead to other errors or unexpected behavior.

  Issue: The current terraform version possibly outdated
  ------------------------------------------------------
  The latest release is version 1.0.5, the project3 configuration requires ~> 0.13.2
  v0.13.2 was released September 02, 2020
  https://github.com/hashicorp/terraform/releases/tag/v0.13.2
  
  Suggestion: Update terraform configuration files
  
  =============================================================================

* Terraform
  Issue: innodb_log_file_size defined as 2097152 is too small, prevents terraform from completing
  
  The innodb_log_file_size terraform parameter in infrastructure-hire-project/project3/terraform/terraform.tfvars needs to be between
  4194304-273804165120, RDS calculates this value based on the instance class defined as db_instance_class
  
    Error: Error modifying DB Parameter Group: InvalidParameterValue: Value: 2097152 is outside of range: 4194304-273804165120 for parameter: innodb_log_file_size
        status code: 400, request id: f64a6204-07cb-45b5-ac69-e2e21ffe376d

  on .terraform/modules/the_app_db.rds/modules/db_parameter_group/main.tf line 33, in resource "aws_db_parameter_group" "this":
  33: resource "aws_db_parameter_group" "this" {
  
  Suggestion: This parameter determines the fixed size for MySQL’s redo logs. Tuning this value affects the crash recovery time and also overall system performance. 
  The default value is 134,217,728 (about 128 MB).
  
  Solution: The value of innodb_log_file_size set to 134217728 in ~/dev/contrast-security/infrastructure-hire-project/project3/terraform/terraform.tfvars

  =============================================================================

* VPC:
  Issue: The vpc is too complicated 
  
  The current terraform configuration for VPC is too complicated, it includes 2 VPCs, 15 subnets, 5 routing table, two network ACLS, 2 internet gateways and 3 security groups.
  To solve any type of routing/networking error will require substantial time to debug and resolve.
  
  Suggestion: Reduce complexit, allow for quicker and easier debugging
  
  =============================================================================
  
* RDS: RDS feature publicly_available does not work, possible routing issue
	Issue: When enabling the RDS feature 'Publicly Available' clients allowed through the security groups are unable to connect, possibly due to routing issue within the VPCs
	       See project3/zareh/bugs/publickly-accessible/rds-mysql-modify-publickly-accessible.png

     Suggestion: Correct subnet routing
     
  =============================================================================

* RDS: db.t3.medium is over provisioned 
    Issue: The instance is over provisioned
    
    The test RDS instance defined in the terraform files is over provisoned, any tuning done to parameter groups
     or schema changes are rendered pointless defeating the purpose of tuning.
    
    Suggestion: Review https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.DBInstanceClass.html and choose a less powerful instance,
    consider .small or .tiny
    
  =============================================================================  

* Database:
    Issue: Increase the amount of rows/data held in the test schema
    
    The schema is too light on data, tools used to determine query performance are unable to provide detailed information
    
    Suggestion: Increase the amount of data provided
    
  =============================================================================
      
* Evaluate using memcached
https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Appendix.MySQL.Options.memcached.html

-------------------------------------------------------------------------------

Final Thoughts

My approach to this project was to build an AWS environment using Terraform which facilitates benchmarking queries using RDS MySQL. 
To accomplish this task I would use the following tools:
  1) MySQL's explain SQL statement
  2) Myysql Workbenche's Execution Plan feature for creating visual diagrams
  3) Percona's toolkit tool pt-query-digest for breaking down query stats

The explain and execution plan tools only required a connection to the mysql instance, so not a lot of configuration was required
besides Terraform's execution. for pt-query-digest a few RDS Parameter Group settings were required to capture the necessary 
information via logging to the mysql-slowquery.log facility.

My approach to benchmarking the queries was to write individual scripts which executed the queires over 100 times to stablish a
baseline for comparison using pt-query-digest. In addition to the indivdual query scripts a general overall script was required
to measure all the queries to identify and compare the performance of all the queries (project3/zareh/sceripts/run-all.sh). 

Once the slowest queries were identified I began looking at the structure of the queries and began reducing the complexity
of the queries to the best of my abilites. This approach was great at identifying the cause/reason for the poor performance
of the queries. I was somewhat succesful at offering suggestions for query_4.sql and query_6.sql but I would need to spend
at least a few more days by approaching the solutions. 

I was better at identifying and adding indexes based on explain and Execution Plan. I believe part of the reaason was the 
simplicity of the queries and also being to translate the results of the tools used to actual actionable items. I was able to 
do this for query_1.sql, query_2.sql, query_5.sql and query_6.sql

The only suggestion I had for query_7.sql is chaning the 'like '%Shipped%' to '= 'Shipped' by looking at the data, as like with
wildcards are more expensive than an equal to.

One issue I ran into was not having enough rows/data to work with in conjuction with an over provisioned instance type, it 
more often than not mask the performance issues of the queries. An idea I had was to reduce the instance type to db.t3.tiny.
An explanation for what the purpose of the queries are, a simple explanation of: I want a report on X Y Z, show us your approch.
Not having this made me hesitant to change the SQL queries.

Overall I found working on project3 very exciting and fun. I wish I had more time to spend on query7 and query4. I have a
few refernces for tuning them, but at this time I'm out of time for the project and need to turn it in and wait for feedback.

I've left a few bugs/actionable items list above and look forward to reviewing everything on our meeting.
